
## Что сделано

Более-менее повторена работа ["Sim. search in high dimensions..."](http://www.vldb.org/conf/1999/P49.pdf) in ("Proc. of 25th VLDB conf", 1999)
Написан питонячий [прототип](https://github.com/nkdhny/lsh/blob/master/etc/hamming.py) для расстояния Хамминга, в форке имеется реализация для `l1`-метрики. Для растояния хамминга есть `c++` библиотека и реализация.

## Подробности реализации на C++

В нулевом порядке посторяет питонячью реализацию, но имеет одну приятную особенность, она умеет работать с разной реализацией двоичных строк, лишь бы для них были определены `SetBit`  и `GetBit` (см. [`lsh.h`](https://github.com/nkdhny/lsh/blob/master/include/binarystring.h))

В частности она умеет работать с разреженными строками к которым применено хеширование признаков

## Почему мне кажется, что это работает адекватно

### Есть некоторое количество тестов

Простые вещи в духе того, что биты выставляются верно и хэши считаются адекватно проверены тестами. Кроме того проверяется, что метод всегда найдет элемент если он есть в выборке. Более сложные утверждения проверять кажется сложно, т. к. они случаются с некоторой вероятностью.

### Есть пример работы в тетрадке

Есть обозримый пример того как метод работает в [тетрадке](https://github.com/nkdhny/lsh/blob/master/etc/sample.ipynb) нельзя сказать что не возникает сомнений относительно того, на сколько такие результаты адекватны, но кажется более-менее приемлимо. В частности

* совсем больших расстояний не получилось
* при уменьшении $R$ т.е. расстояния в котором мы ищем соседей, уменьшается число найденных римеров (поиск ближайшего соседа становится точнее)
* при увеличении числа бит, число найденных примеров падает (по аналигичным причинам)
* при увеличении числа минихэшей распределение расстояний сдвигается в сторону истинного распределения расстояний

## Как это собирать

Как обычно

```bash
mkdir ./build
cd ./build
cmake ..
make
```
Понадобятся библиотеки `boost` версии `1.63` или надо поменять их в [`CMakeLists`](https://github.com/nkdhny/lsh/blob/master/CMakeLists.txt)

## Как это работает на данных побольше

Я нагенерировал случайных данных, достаточно разреженных, с вероятностью взведения каждого из 4096 бит 0.01, 100000 примеров для тренировки и 10000 для теста, просил найти 256 соседей. Памяти это не занимает почти нисколько (сравни с питоном и плотными матрицами для `KNN`: около 3ГБ). После очень продолжительной предобработки запрос занял около шести минут. Питонячей версии честного `KNN` из `sklearn` на поиск соселей понадобилось 

## Впечатления от метода

Мне как-то не очень понравился метод, на то есь несколько причин

### Странные параметры
По хорошему метод параметризован параметрами $r_1$
